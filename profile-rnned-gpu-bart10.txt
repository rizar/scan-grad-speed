Using gpu device 0: GeForce GTX TITAN
/u/bahdanau/Dist/theano/theano/scan_module/scan_perform_ext.py:117: RuntimeWarning: numpy.ndarray size changed, may indicate binary incompatibility
  from scan_perform.scan_perform import *
Function profiling
==================
  Message: ./demo.py:61
  Time in 5 calls to Function.__call__: 1.516788e+00s
  Time in Function.fn.__call__: 1.516413e+00s (99.975%)
  Time in thunks: 1.514982e+00s (99.881%)
  Total compile time: 4.377977e+00s
    Number of Apply nodes: 61
    Theano Optimizer time: 3.847871e+00s
       Theano validate time: 1.933956e-02s
    Theano Linker time (includes C, CUDA code generation/compiling): 5.168049e-01s

Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  95.2%    95.2%       1.442s       1.44e-01s     Py      10       2   theano.scan_module.scan_op.Scan
   3.7%    98.9%       0.056s       1.60e-03s     C       35       7   theano.sandbox.cuda.basic_ops.GpuFromHost
   0.5%    99.4%       0.008s       8.05e-04s     C       10       2   theano.sandbox.cuda.basic_ops.GpuAlloc
   0.4%    99.8%       0.006s       3.73e-04s     C       15       3   theano.tensor.basic.Alloc
   0.1%    99.9%       0.002s       1.57e-04s     C       10       2   theano.sandbox.cuda.basic_ops.GpuIncSubtensor
   0.1%    99.9%       0.001s       9.87e-05s     C       10       2   theano.sandbox.cuda.basic_ops.GpuElemwise
   0.0%   100.0%       0.001s       4.72e-05s     Py      15       3   theano.sandbox.cuda.basic_ops.GpuReshape
   0.0%   100.0%       0.000s       2.88e-06s     C       50      10   theano.sandbox.cuda.basic_ops.GpuSubtensor
   0.0%   100.0%       0.000s       2.49e-06s     C       50      10   theano.tensor.elemwise.Elemwise
   0.0%   100.0%       0.000s       2.10e-06s     C       35       7   theano.compile.ops.Shape_i
   0.0%   100.0%       0.000s       1.92e-06s     C       30       6   theano.sandbox.cuda.basic_ops.GpuDimShuffle
   0.0%   100.0%       0.000s       1.41e-06s     C       20       4   theano.tensor.basic.ScalarFromTensor
   0.0%   100.0%       0.000s       1.41e-06s     C       15       3   theano.compile.ops.Rebroadcast
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  79.1%    79.1%       1.198s       2.40e-01s     Py       5        1   forall_inplace,gpu,grad_of_layer_rec}
  16.1%    95.2%       0.243s       4.86e-02s     Py       5        1   for{gpu,layer_rec}
   3.7%    98.9%       0.056s       1.60e-03s     C       35        7   GpuFromHost
   0.5%    99.4%       0.008s       8.05e-04s     C       10        2   GpuAlloc{memset_0=True}
   0.4%    99.8%       0.006s       3.73e-04s     C       15        3   Alloc
   0.1%    99.8%       0.001s       2.80e-04s     C        5        1   GpuIncSubtensor{InplaceInc;int64::}
   0.1%    99.9%       0.001s       9.87e-05s     C       10        2   GpuElemwise{sub,no_inplace}
   0.0%   100.0%       0.001s       4.72e-05s     Py      15        3   GpuReshape{3}
   0.0%   100.0%       0.000s       3.30e-05s     C        5        1   GpuIncSubtensor{InplaceInc;int64}
   0.0%   100.0%       0.000s       2.71e-06s     C       25        5   GpuSubtensor{int64:int64:int64}
   0.0%   100.0%       0.000s       2.54e-06s     C       20        4   Shape_i{0}
   0.0%   100.0%       0.000s       2.11e-06s     C       15        3   GpuSubtensor{int64}
   0.0%   100.0%       0.000s       1.41e-06s     C       20        4   ScalarFromTensor
   0.0%   100.0%       0.000s       1.68e-06s     C       15        3   GpuDimShuffle{1,0}
   0.0%   100.0%       0.000s       5.01e-06s     C        5        1   GpuSubtensor{::int64}
   0.0%   100.0%       0.000s       1.51e-06s     C       15        3   Shape_i{1}
   0.0%   100.0%       0.000s       2.19e-06s     C       10        2   GpuDimShuffle{0,1,x}
   0.0%   100.0%       0.000s       1.41e-06s     C       15        3   Rebroadcast{0}
   0.0%   100.0%       0.000s       3.96e-06s     C        5        1   GpuSubtensor{int64:int64:int8}
   0.0%   100.0%       0.000s       3.96e-06s     C        5        1   Elemwise{Composite{[Switch(LT(*1 -> Composite{[Switch(LT(i0, i1), i1, i0)]}(Composite{[Switch(LT(i0, i1), i2, i0)]}(Composite{[sub(i0, Switch(LT(i1, i2), i2, i1))]}(i0, Composite{[add(i0, int_div(i1, i0))]}(i1, *2 -> add(i2, i0)), i3), i3, *2), i3), i4), *1, i4)]}}
   ... (remaining 9 Ops account for   0.01%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  79.1%    79.1%       1.198s       2.40e-01s      5    57   forall_inplace,gpu,grad_of_layer_rec}(TensorConstant{50}, GpuDimShuffle{0,2,1}.0, GpuDimShuffle{0,1,x}.0, GpuElemwise{sub,no_inplace}.0, GpuSubtensor{int64:int64:int64}.0, GpuSubtensor{int64:int64:int64}.0, GpuSubtensor{int64:int64:int64}.0, GpuSubtensor{int64:int64:int64}.0, GpuSubtensor{::int64}.0, GpuFromHost.0, GpuFromHost.0, GpuFromHost.0, G_rec, R_rec, W_rec, GpuDimShuffle{1,0}.0, GpuDimShuffle{1,0}.0, GpuDimShuffle{1,0}.0)
  16.1%    95.2%       0.243s       4.86e-02s      5    54   for{gpu,layer_rec}(TensorConstant{50}, GpuDimShuffle{0,1,x}.0, GpuElemwise{sub,no_inplace}.0, GpuReshape{3}.0, GpuReshape{3}.0, GpuReshape{3}.0, CudaNdarrayConstant{[[[ 0.  0.  0. ...,  0.  0.  0.]
  [ 0.  0.  0. ...,  0.  0.  0.]
  [ 0.  0.  0. ...,  0.  0.  0.]
  ..., 
  [ 0.  0.  0. ...,  0.  0.  0.]
  [ 0.  0.  0. ...,  0.  0.  0.]
  [ 0.  0.  0. ...,  0.  0.  0.]]

 [[ 0.  0.  0. ...,  0.  0.  0.]
  [ 0.  0.  0. ...,  0.  0.  0.]
  [ 0.  0.  0.
   1.0%    96.1%       0.015s       2.96e-03s      5    12   GpuFromHost(zi)
   1.0%    97.1%       0.015s       2.94e-03s      5    11   GpuFromHost(ri)
   1.0%    98.1%       0.015s       2.92e-03s      5    13   GpuFromHost(x)
   0.4%    98.5%       0.007s       1.34e-03s      5     1   GpuAlloc{memset_0=True}(CudaNdarrayConstant{[[[ 0.]]]}, TensorConstant{51}, TensorConstant{80}, TensorConstant{1000})
   0.3%    98.8%       0.004s       7.92e-04s      5    34   GpuFromHost(Rebroadcast{0}.0)
   0.3%    99.0%       0.004s       7.88e-04s      5    36   GpuFromHost(Rebroadcast{0}.0)
   0.3%    99.3%       0.004s       7.81e-04s      5    35   GpuFromHost(Rebroadcast{0}.0)
   0.2%    99.4%       0.002s       4.76e-04s      5    17   Alloc(TensorConstant{0.0}, TensorConstant{1}, Shape_i{0}.0, Shape_i{1}.0)
   0.1%    99.5%       0.002s       3.22e-04s      5    18   Alloc(TensorConstant{0.0}, TensorConstant{1}, Shape_i{0}.0, Shape_i{1}.0)
   0.1%    99.7%       0.002s       3.21e-04s      5    19   Alloc(TensorConstant{0.0}, TensorConstant{1}, Shape_i{0}.0, Shape_i{1}.0)
   0.1%    99.7%       0.001s       2.80e-04s      5    24   GpuIncSubtensor{InplaceInc;int64::}(GpuAlloc{memset_0=True}.0, GpuIncSubtensor{InplaceInc;int64}.0, Constant{1})
   0.1%    99.8%       0.001s       2.72e-04s      5     0   GpuAlloc{memset_0=True}(CudaNdarrayConstant{[[[ 0.]]]}, TensorConstant{50}, TensorConstant{80}, TensorConstant{1000})
   0.0%    99.9%       0.001s       1.14e-04s      5    53   GpuElemwise{sub,no_inplace}(CudaNdarrayConstant{[[[ 1.]]]}, GpuDimShuffle{0,1,x}.0)
   0.0%    99.9%       0.000s       8.34e-05s      5    52   GpuElemwise{sub,no_inplace}(CudaNdarrayConstant{[[[ 1.]]]}, GpuDimShuffle{0,1,x}.0)
   0.0%    99.9%       0.000s       4.98e-05s      5    22   GpuReshape{3}(GpuFromHost.0, TensorConstant{[  50   80 1000]})
   0.0%    99.9%       0.000s       4.66e-05s      5    21   GpuReshape{3}(GpuFromHost.0, TensorConstant{[  50   80 1000]})
   0.0%    99.9%       0.000s       4.53e-05s      5    20   GpuReshape{3}(GpuFromHost.0, TensorConstant{[  50   80 1000]})
   0.0%   100.0%       0.000s       3.62e-05s      5    15   GpuFromHost(mask)
   ... (remaining 41 Apply instances account for 0.04%(0.00s) of the runtime)


Scan Op profiling ( layer_rec )
==================
  Message: None
  Time in 5 calls of the op (for a total of 250 steps) 2.427378e-01s

  Total time spent in calling the VM 2.138805e-01s (88.112%)
  Total overhead (computing slices..) 2.885723e-02s (11.888%)

Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  90.7%    90.7%       0.185s       2.46e-04s     C      750       3   theano.sandbox.cuda.blas.GpuGemm
   9.3%   100.0%       0.019s       3.79e-05s     C      500       2   theano.sandbox.cuda.basic_ops.GpuElemwise
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  90.7%    90.7%       0.185s       2.46e-04s     C      750        3   GpuGemm{no_inplace}
   5.8%    96.5%       0.012s       4.70e-05s     C      250        1   GpuElemwise{Composite{[add(mul(i0, add(mul(*1 -> scalar_sigmoid(i1), tanh(i2)), mul(sub(i3, *1), i4))), mul(i5, i4))]}}[(0, 1)]
   3.5%   100.0%       0.007s       2.88e-05s     C      250        1   GpuElemwise{Composite{[mul(scalar_sigmoid(i0), i1)]}}[(0, 0)]
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  36.6%    36.6%       0.074s       2.98e-04s    250     3   GpuGemm{no_inplace}(<CudaNdarrayType(float32, matrix)>, TensorConstant{1.0}, GpuElemwise{Composite{[mul(scalar_sigmoid(i0), i1)]}}[(0, 0)].0, W_rec_copy[cuda], TensorConstant{1.0})
  27.2%    63.8%       0.055s       2.21e-04s    250     0   GpuGemm{no_inplace}(<CudaNdarrayType(float32, matrix)>, TensorConstant{1.0}, <CudaNdarrayType(float32, matrix)>, R_rec_copy[cuda], TensorConstant{1.0})
  26.9%    90.7%       0.055s       2.19e-04s    250     1   GpuGemm{no_inplace}(<CudaNdarrayType(float32, matrix)>, TensorConstant{1.0}, <CudaNdarrayType(float32, matrix)>, G_rec_copy[cuda], TensorConstant{1.0})
   5.8%    96.5%       0.012s       4.70e-05s    250     4   GpuElemwise{Composite{[add(mul(i0, add(mul(*1 -> scalar_sigmoid(i1), tanh(i2)), mul(sub(i3, *1), i4))), mul(i5, i4))]}}[(0, 1)](<CudaNdarrayType(float32, col)>, GpuGemm{no_inplace}.0, GpuGemm{no_inplace}.0, CudaNdarrayConstant{[[ 1.]]}, <CudaNdarrayType(float32, matrix)>, <CudaNdarrayType(float32, col)>)
   3.5%   100.0%       0.007s       2.88e-05s    250     2   GpuElemwise{Composite{[mul(scalar_sigmoid(i0), i1)]}}[(0, 0)](GpuGemm{no_inplace}.0, <CudaNdarrayType(float32, matrix)>)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)


Scan Op profiling ( grad_of_layer_rec )
==================
  Message: None
  Time in 5 calls of the op (for a total of 250 steps) 1.197829e+00s

  Total time spent in calling the VM 1.016510e+00s (84.863%)
  Total overhead (computing slices..) 1.813185e-01s (15.137%)

Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  70.3%    70.3%       0.677s       3.87e-04s     C     1750       7   theano.sandbox.cuda.blas.GpuGemm
  18.7%    89.0%       0.181s       7.22e-05s     C     2500      10   theano.sandbox.cuda.basic_ops.GpuElemwise
  10.9%    99.9%       0.105s       2.10e-04s     C      500       2   theano.sandbox.cuda.blas.GpuDot22
   0.1%   100.0%       0.001s       2.02e-06s     C      250       1   theano.sandbox.cuda.basic_ops.GpuDimShuffle
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  64.9%    64.9%       0.625s       4.17e-04s     C     1500        6   GpuGemm{no_inplace}
  10.9%    75.8%       0.105s       2.10e-04s     C      500        2   GpuDot22
   6.3%    82.2%       0.061s       1.22e-04s     C      500        2   GpuElemwise{mul,no_inplace}
   5.7%    87.9%       0.055s       2.19e-04s     C      250        1   GpuElemwise{Composite{[mul(mul(mul(i0, i1), i2), sub(i3, i2))]},no_inplace}
   5.4%    93.2%       0.052s       2.07e-04s     C      250        1   GpuGemm{inplace}
   2.5%    95.8%       0.025s       9.81e-05s     C      250        1   GpuElemwise{sub,no_inplace}
   1.3%    97.0%       0.012s       2.42e-05s     C      500        2   GpuElemwise{ScalarSigmoid}[(0, 0)]
   1.0%    98.0%       0.009s       3.66e-05s     C      250        1   GpuElemwise{Composite{[add(mul(i0, i1), mul(i2, i3), mul(i4, i5), i6, i7)]}}[(0, 0)]
   0.8%    98.8%       0.008s       3.25e-05s     C      250        1   GpuElemwise{Composite{[mul(mul(add(mul(i0, i1), neg(mul(i0, i2))), i3), i4)]},no_inplace}
   0.6%    99.4%       0.006s       2.23e-05s     C      250        1   GpuElemwise{Tanh}[(0, 0)]
   0.5%    99.9%       0.005s       2.06e-05s     C      250        1   GpuElemwise{Composite{[mul(mul(i0, i1), sub(i2, sqr(i3)))]}}[(0, 1)]
   0.1%   100.0%       0.001s       2.02e-06s     C      250        1   GpuDimShuffle{1,0}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  15.6%    15.6%       0.150s       5.99e-04s    250    17   GpuGemm{no_inplace}(<CudaNdarrayType(float32, matrix)>, TensorConstant{1.0}, <CudaNdarrayType(float32, matrix)>, GpuElemwise{Composite{[mul(mul(mul(i0, i1), i2), sub(i3, i2))]},no_inplace}.0, TensorConstant{1.0})
  15.4%    30.9%       0.148s       5.91e-04s    250    12   GpuGemm{no_inplace}(<CudaNdarrayType(float32, matrix)>, TensorConstant{1.0}, <CudaNdarrayType(float32, matrix)>, GpuElemwise{Composite{[mul(mul(add(mul(i0, i1), neg(mul(i0, i2))), i3), i4)]},no_inplace}.0, TensorConstant{1.0})
  15.2%    46.1%       0.146s       5.84e-04s    250    14   GpuGemm{no_inplace}(<CudaNdarrayType(float32, matrix)>, TensorConstant{1.0}, GpuDimShuffle{1,0}.0, GpuElemwise{Composite{[mul(mul(i0, i1), sub(i2, sqr(i3)))]}}[(0, 1)].0, TensorConstant{1.0})
   7.2%    53.3%       0.070s       2.79e-04s    250     0   GpuGemm{no_inplace}(<CudaNdarrayType(float32, matrix)>, TensorConstant{1.0}, <CudaNdarrayType(float32, matrix)>, G_rec_copy[cuda], TensorConstant{1.0})
   5.9%    59.2%       0.057s       2.28e-04s    250     7   GpuGemm{no_inplace}(<CudaNdarrayType(float32, matrix)>, TensorConstant{1.0}, GpuElemwise{mul,no_inplace}.0, W_rec_copy[cuda], TensorConstant{1.0})
   5.7%    64.9%       0.055s       2.19e-04s    250    16   GpuElemwise{Composite{[mul(mul(mul(i0, i1), i2), sub(i3, i2))]},no_inplace}(GpuDot22.0, <CudaNdarrayType(float32, matrix)>, GpuElemwise{ScalarSigmoid}[(0, 0)].0, CudaNdarrayConstant{[[ 1.]]})
   5.7%    70.6%       0.055s       2.19e-04s    250     1   GpuGemm{no_inplace}(<CudaNdarrayType(float32, matrix)>, TensorConstant{1.0}, <CudaNdarrayType(float32, matrix)>, R_rec_copy[cuda], TensorConstant{1.0})
   5.7%    76.3%       0.055s       2.18e-04s    250    13   GpuDot22(GpuElemwise{Composite{[mul(mul(add(mul(i0, i1), neg(mul(i0, i2))), i3), i4)]},no_inplace}.0, G_rec_copy.T_replace[cuda])
   5.4%    81.7%       0.052s       2.08e-04s    250     6   GpuElemwise{mul,no_inplace}(GpuElemwise{ScalarSigmoid}[(0, 0)].0, <CudaNdarrayType(float32, matrix)>)
   5.4%    87.0%       0.052s       2.07e-04s    250    18   GpuGemm{inplace}(GpuDot22.0, TensorConstant{1.0}, GpuElemwise{Composite{[mul(mul(mul(i0, i1), i2), sub(i3, i2))]},no_inplace}.0, R_rec_copy.T_replace[cuda], TensorConstant{1.0})
   5.2%    92.3%       0.051s       2.02e-04s    250    15   GpuDot22(GpuElemwise{Composite{[mul(mul(i0, i1), sub(i2, sqr(i3)))]}}[(0, 1)].0, W_rec_copy.T_replace[cuda])
   2.5%    94.8%       0.025s       9.81e-05s    250     5   GpuElemwise{sub,no_inplace}(CudaNdarrayConstant{[[ 1.]]}, GpuElemwise{ScalarSigmoid}[(0, 0)].0)
   1.0%    95.8%       0.009s       3.66e-05s    250    19   GpuElemwise{Composite{[add(mul(i0, i1), mul(i2, i3), mul(i4, i5), i6, i7)]}}[(0, 0)](GpuDot22.0, GpuElemwise{ScalarSigmoid}[(0, 0)].0, GpuElemwise{mul,no_inplace}.0, GpuElemwise{sub,no_inplace}.0, <CudaNdarrayType(float32, matrix)>, <CudaNdarrayType(float32, col)>, <CudaNdarrayType(float32, matrix)>, GpuGemm{inplace}.0)
   0.9%    96.7%       0.009s       3.63e-05s    250     2   GpuElemwise{mul,no_inplace}(<CudaNdarrayType(float32, matrix)>, <CudaNdarrayType(float32, col)>)
   0.8%    97.6%       0.008s       3.25e-05s    250    10   GpuElemwise{Composite{[mul(mul(add(mul(i0, i1), neg(mul(i0, i2))), i3), i4)]},no_inplace}(GpuElemwise{mul,no_inplace}.0, GpuElemwise{Tanh}[(0, 0)].0, <CudaNdarrayType(float32, matrix)>, GpuElemwise{ScalarSigmoid}[(0, 0)].0, GpuElemwise{sub,no_inplace}.0)
   0.6%    98.2%       0.006s       2.49e-05s    250     3   GpuElemwise{ScalarSigmoid}[(0, 0)](GpuGemm{no_inplace}.0)
   0.6%    98.8%       0.006s       2.35e-05s    250     4   GpuElemwise{ScalarSigmoid}[(0, 0)](GpuGemm{no_inplace}.0)
   0.6%    99.4%       0.006s       2.23e-05s    250     9   GpuElemwise{Tanh}[(0, 0)](GpuGemm{no_inplace}.0)
   0.5%    99.9%       0.005s       2.06e-05s    250    11   GpuElemwise{Composite{[mul(mul(i0, i1), sub(i2, sqr(i3)))]}}[(0, 1)](GpuElemwise{mul,no_inplace}.0, GpuElemwise{ScalarSigmoid}[(0, 0)].0, CudaNdarrayConstant{[[ 1.]]}, GpuElemwise{Tanh}[(0, 0)].0)
   0.1%   100.0%       0.001s       2.02e-06s    250     8   GpuDimShuffle{1,0}(GpuElemwise{mul,no_inplace}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

